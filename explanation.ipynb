{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use user_classification.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First import the module and initialize a twitter api if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from user_classification import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import twitter\n",
    "\n",
    "CONSUMER_KEY = 'oEWIMZpIUQCULqXLVAydLsUoT'\n",
    "CONSUMER_SECRET = 'F31ZPD7rRlzkrsbmE5JqMs8tWQjLrD3TxkNObNNeHz2nBbDwnt'\n",
    "OAUTH_TOKEN = '1303957818169585664-5xyRbIo7kcM19IQjT7t2OdtBS5G0hw'\n",
    "OAUTH_TOKEN_SECRET = 'WKZNyiVxqMyfxL3JoHiaU30axOrpGu7YasKjtmYhnz2Ym'\n",
    "\n",
    "auth = twitter.oauth.OAuth(OAUTH_TOKEN,\n",
    "                          OAUTH_TOKEN_SECRET, \n",
    "                          CONSUMER_KEY, \n",
    "                          CONSUMER_SECRET)\n",
    "\n",
    "twitter_api = twitter.Twitter(auth=auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will initialize a dataset object.\n",
    "\n",
    "If a new dataset is needed, we will need a csv with labelled data. It must have at least two columns:\n",
    "- `screen_name`: column with user accounts.\n",
    "- `label`: column with the user label.\n",
    "\n",
    "If we want to load an old dataset, we will make use of the `load` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataset = False\n",
    "csv_path = 'Data/labelled_users.csv'\n",
    "user_column = 'screen_name'\n",
    "label_column = 'clas_1'\n",
    "\n",
    "def lowercase(x):\n",
    "    return x.lower()\n",
    "\n",
    "if new_dataset:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    user = list(df[user_column].to_numpy())\n",
    "    label = list(df[label_column].to_numpy())\n",
    "    label = [lowercase(x) for x in label]\n",
    "    dataset.add_list_user(twitter_api, user, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_dataset_path = 'Data/test.csv'\n",
    "\n",
    "if not new_dataset:\n",
    "    dataset.load(path=old_dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the dataset by printing the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>collective_activeness</th>\n",
       "      <th>collective_influence</th>\n",
       "      <th>degree_inclination</th>\n",
       "      <th>fav_count</th>\n",
       "      <th>label</th>\n",
       "      <th>life_time</th>\n",
       "      <th>mentions</th>\n",
       "      <th>plain_statuses</th>\n",
       "      <th>promotion_score</th>\n",
       "      <th>replies_given</th>\n",
       "      <th>retweets</th>\n",
       "      <th>std_hashtags</th>\n",
       "      <th>std_url</th>\n",
       "      <th>total_hashtag</th>\n",
       "      <th>total_url</th>\n",
       "      <th>user</th>\n",
       "      <th>verified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>497.6</td>\n",
       "      <td>651.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>573.0</td>\n",
       "      <td>personal</td>\n",
       "      <td>9.188227</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.674949</td>\n",
       "      <td>0.421637</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>RepsolJackLeeds</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1080.9</td>\n",
       "      <td>6275.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>5423.0</td>\n",
       "      <td>personal</td>\n",
       "      <td>2.617385</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.108185</td>\n",
       "      <td>0.316228</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>artemania2018</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4866.6</td>\n",
       "      <td>49343.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2278.0</td>\n",
       "      <td>corporative</td>\n",
       "      <td>9.577002</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.843274</td>\n",
       "      <td>0.483046</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Repsol</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3287.2</td>\n",
       "      <td>1197.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>902.0</td>\n",
       "      <td>personal</td>\n",
       "      <td>10.830938</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.763834</td>\n",
       "      <td>0.516398</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>JuanBellas</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>943.7</td>\n",
       "      <td>324.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>19.0</td>\n",
       "      <td>personal</td>\n",
       "      <td>9.979466</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.843274</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>tarteka</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   collective_activeness  collective_influence  degree_inclination  fav_count  \\\n",
       "0                  497.6                 651.0                 4.8      573.0   \n",
       "1                 1080.9                6275.0                 1.8     5423.0   \n",
       "2                 4866.6               49343.0                 0.0     2278.0   \n",
       "3                 3287.2                1197.0                 4.2      902.0   \n",
       "4                  943.7                 324.0                 3.2       19.0   \n",
       "\n",
       "         label  life_time  mentions  plain_statuses  promotion_score  \\\n",
       "0     personal   9.188227      14.0             0.0             10.0   \n",
       "1     personal   2.617385       2.0             0.0             17.0   \n",
       "2  corporative   9.577002       9.0             0.0             17.0   \n",
       "3     personal  10.830938       5.0             0.0             23.0   \n",
       "4     personal   9.979466      10.0             0.0             13.0   \n",
       "\n",
       "   replies_given  retweets  std_hashtags   std_url  total_hashtag  total_url  \\\n",
       "0            2.0       6.0      0.674949  0.421637            3.0        2.0   \n",
       "1            0.0       1.0      2.108185  0.316228           40.0        1.0   \n",
       "2            0.0       0.0      0.843274  0.483046            4.0        3.0   \n",
       "3            1.0       3.0      1.763834  0.516398           10.0        4.0   \n",
       "4            0.0       8.0      0.843274  0.000000            6.0        0.0   \n",
       "\n",
       "              user  verified  \n",
       "0  RepsolJackLeeds       0.0  \n",
       "1    artemania2018       0.0  \n",
       "2           Repsol       1.0  \n",
       "3       JuanBellas       0.0  \n",
       "4          tarteka       0.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can save the dataset by calling to the `save` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "save = False\n",
    "dataset_path = 'Data/test.csv'\n",
    "\n",
    "if save:\n",
    "    dataset.save(path=dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will get the training data and we must specify if we want one-hot encoding (for multi-class classification) or not (for binary classification) by passing `to_categorical` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_categorical = False\n",
    "\n",
    "data = dataset.get_training_data(test_size = 0.2, \n",
    "                                 to_categorical=to_categorical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can initialize a model by specifying the `model_type`. Then, we can train the model by providing the `data` object and calling the `train` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 128)               2048      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 129       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 18,689\n",
      "Trainable params: 18,689\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "possible_type = ['random_forest',\n",
    "                 'mlp',\n",
    "                 'mlp_binary']\n",
    "\n",
    "model_type = possible_type[2]\n",
    "\n",
    "model = Model(model_type=model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.5942 - accuracy: 0.6833\n",
      "Epoch 2/12\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.4656 - accuracy: 0.8333\n",
      "Epoch 3/12\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.3815 - accuracy: 0.8500\n",
      "Epoch 4/12\n",
      "60/60 [==============================] - 0s 6ms/step - loss: 0.3557 - accuracy: 0.8417\n",
      "Epoch 5/12\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.3230 - accuracy: 0.8667\n",
      "Epoch 6/12\n",
      "60/60 [==============================] - 0s 5ms/step - loss: 0.3046 - accuracy: 0.8417\n",
      "Epoch 7/12\n",
      "60/60 [==============================] - 0s 5ms/step - loss: 0.3211 - accuracy: 0.8750\n",
      "Epoch 8/12\n",
      "60/60 [==============================] - 0s 5ms/step - loss: 0.2784 - accuracy: 0.8917\n",
      "Epoch 9/12\n",
      "60/60 [==============================] - 0s 5ms/step - loss: 0.2780 - accuracy: 0.9000\n",
      "Epoch 10/12\n",
      "60/60 [==============================] - 0s 5ms/step - loss: 0.2892 - accuracy: 0.8833\n",
      "Epoch 11/12\n",
      "60/60 [==============================] - 0s 5ms/step - loss: 0.2491 - accuracy: 0.9083\n",
      "Epoch 12/12\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2477 - accuracy: 0.9000\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 12\n",
    "\n",
    "model.train(data, n_epochs=n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 5ms/step - loss: 0.2228 - accuracy: 0.8667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.22284862399101257, 0.8666666746139526]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(data) # get the test_set accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can save the model for latter use by providing a `name`. The model will be saved to checkpoints/`<model_type>`/`<name> (w/o extension)`/`<name>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = '16_09_v1.h5'\n",
    "\n",
    "model.save(name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Class to build, train and use models for classification. There are different types of models:\n",
      "    ['random_forest', 'mlp', 'mlp_binary']\n",
      "\n",
      "    ...\n",
      "\n",
      "    Methods\n",
      "    -------\n",
      "    build:\n",
      "        build the model depending on the model_type choosen.\n",
      "    train: (data: data object)\n",
      "        trains the model with the given data.\n",
      "    evaluate: (data: data object)\n",
      "        returns an evaluation of the model given a test data.\n",
      "    predict: (x: iterable - np.array)\n",
      "        returns the prediction for new data.\n",
      "    save: (path: str)\n",
      "        saves the model for later use.\n",
      "    load: (path: str)\n",
      "        loads a pretrained model.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(model.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Class to handle the dataset and obtain the data from the twitter API.\n",
      "\n",
      "    ...\n",
      "\n",
      "    Methods\n",
      "    -------\n",
      "    load: (path: str)\n",
      "        Loads an existing dataset saved in a csv.\n",
      "    add_list_user: (twitter_api: twitter object, users: list, labels: list, force: bool)\n",
      "        Add users from a list of screen_name (unique for Twitter) and, if needed, with the corresponding\n",
      "        label for each user.\n",
      "    add_user: (twitter_api: twitter object, users: list, labels: list, force: bool)\n",
      "        Add users from a list of screen_name (unique for Twitter) and, if needed, with the corresponding\n",
      "        label for each user.\n",
      "    get_training_data: (columns: list, test_size: int)\n",
      "        Returns a data object with the training and test data.\n",
      "    get_data: (columns: list)\n",
      "        Returns a np.array with the columns specified from the df.\n",
      "    save: (path: str)\n",
      "        Saves the dataframe into a csv file to be used latter. If the df was previously loaded,\n",
      "        it will save at the same path if not specified differently.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(dataset.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Class to handle splitting, normalizing, encoding ... data to input to the models.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(data.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
